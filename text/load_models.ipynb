{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118b485a",
   "metadata": {},
   "source": [
    "# This notebook contains Step 2 : Answer Generation and  Step 3 Assertions part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6816395-caef-48a4-b11c-83a509b533ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 10:26:50.753258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758900410.772347 3999145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758900410.778159 3999145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-26 10:26:50.805590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  \n",
    "from sentence_transformers import CrossEncoder\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee791dc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "import warnings\n",
    "from transformers.utils import logging as hf_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45234950-067b-486c-8a05-bdab5d015860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fbdcec-68f7-4254-8961-0d296081aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e61c74",
   "metadata": {},
   "source": [
    "### Fetch data from the ChromaDb Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608d7aba-e281-4fe3-9fb0-b003cdb75d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./ChromaDb\")\n",
    "collection_name = \"qasper_data_collection\"\n",
    "\n",
    "chroma_collection = chroma_client.get_collection(collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0691b560-9e29-438b-8f5e-521d100e57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_qasper = pd.read_csv('processed_qasper_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b16e3ed-c3b5-4c02-a85a-47c2cea19707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>nlp_background</th>\n",
       "      <th>topic_background</th>\n",
       "      <th>paper_read</th>\n",
       "      <th>search_query</th>\n",
       "      <th>question_writer</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>unanswerable</th>\n",
       "      <th>yes_no</th>\n",
       "      <th>free_form_answer</th>\n",
       "      <th>extractive_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>highlighted_evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>753990d0b621d390ed58f20c4d9e4f065f0dc672</td>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>31e85022a847f37c15fd0415f3c450c74c8e4755</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a vocabulary of positive and negative predicat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>9d578ddccc27dd849244d632dd0f6bf27348ad81</td>\n",
       "      <td>What are the results?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>1e5e867244ea656c4b7632628086209cf9bae5fa</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>49a78a07d2eed545556a835ccf2eb40e5eee9801</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>based on the relation between events, the sugg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cause relation: both events in the relation sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>44c4bd6decc86f1091b5fc0728873d9324cdde4e</td>\n",
       "      <td>How big is the Japanese data?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>36926a4c9e14352c91111150aa4c6edcc5c0770f</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7000000 pairs of events were extracted from th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "1  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "2  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "3  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "4  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Recognizing affective events that trigger posi...   \n",
       "1  Recognizing affective events that trigger posi...   \n",
       "2  Recognizing affective events that trigger posi...   \n",
       "3  Recognizing affective events that trigger posi...   \n",
       "4  Recognizing affective events that trigger posi...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "1  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "2  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "3  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "4  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "\n",
       "                                question_id  \\\n",
       "0  753990d0b621d390ed58f20c4d9e4f065f0dc672   \n",
       "1  9d578ddccc27dd849244d632dd0f6bf27348ad81   \n",
       "2  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "3  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "4  44c4bd6decc86f1091b5fc0728873d9324cdde4e   \n",
       "\n",
       "                                        question nlp_background  \\\n",
       "0                      What is the seed lexicon?            two   \n",
       "1                          What are the results?            two   \n",
       "2  How are relations used to propagate polarity?            two   \n",
       "3  How are relations used to propagate polarity?            two   \n",
       "4                  How big is the Japanese data?            two   \n",
       "\n",
       "  topic_background paper_read search_query  \\\n",
       "0       unfamiliar         no          NaN   \n",
       "1       unfamiliar         no          NaN   \n",
       "2       unfamiliar         no          NaN   \n",
       "3       unfamiliar         no          NaN   \n",
       "4       unfamiliar         no          NaN   \n",
       "\n",
       "                            question_writer  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "1  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "2  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "3  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "4  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "\n",
       "                              annotation_id  \\\n",
       "0  31e85022a847f37c15fd0415f3c450c74c8e4755   \n",
       "1  1e5e867244ea656c4b7632628086209cf9bae5fa   \n",
       "2  49a78a07d2eed545556a835ccf2eb40e5eee9801   \n",
       "3  acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1   \n",
       "4  36926a4c9e14352c91111150aa4c6edcc5c0770f   \n",
       "\n",
       "                                  worker_id  unanswerable  yes_no  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False     NaN   \n",
       "1  2cfd959e433f290bb50b55722370f0d22fe090b7         False     NaN   \n",
       "2  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False     NaN   \n",
       "3  2cfd959e433f290bb50b55722370f0d22fe090b7         False     NaN   \n",
       "4  2cfd959e433f290bb50b55722370f0d22fe090b7         False     NaN   \n",
       "\n",
       "                                    free_form_answer  extractive_spans  \\\n",
       "0  a vocabulary of positive and negative predicat...               NaN   \n",
       "1  Using all data to train: AL -- BiGRU achieved ...               NaN   \n",
       "2  based on the relation between events, the sugg...               NaN   \n",
       "3  cause relation: both events in the relation sh...               NaN   \n",
       "4  7000000 pairs of events were extracted from th...               NaN   \n",
       "\n",
       "                                            evidence  \\\n",
       "0  The seed lexicon consists of positive and nega...   \n",
       "1  FLOAT SELECTED: Table 3: Performance of variou...   \n",
       "2  In this paper, we propose a simple and effecti...   \n",
       "3  In this paper, we propose a simple and effecti...   \n",
       "4  As a raw corpus, we used a Japanese web corpus...   \n",
       "\n",
       "                                highlighted_evidence  \n",
       "0  The seed lexicon consists of positive and nega...  \n",
       "1  FLOAT SELECTED: Table 3: Performance of variou...  \n",
       "2  As illustrated in Figure FIGREF1, our key idea...  \n",
       "3  As illustrated in Figure FIGREF1, our key idea...  \n",
       "4  As a raw corpus, we used a Japanese web corpus...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_qasper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b570184b-3c97-494d-a694-b98d192e4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only rows with a question\n",
    "questions = (\n",
    "    questions_qasper.groupby(\"question_id\")\n",
    "      .first()                                     \n",
    "      .reset_index()[[\"question_id\",\"question\",\n",
    "                      \"paper_id\",\"free_form_answer\"]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375002eb-6630-4797-94db-444ea7c62284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>free_form_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0038b073b7cca847033177024f9719c971692042</td>\n",
       "      <td>How is the input triple translated to a slot-f...</td>\n",
       "      <td>1706.04115</td>\n",
       "      <td>The relation R(x,y) is mapped onto a question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bcdffff7e055f99aaf1b05cf41c98e2748e948</td>\n",
       "      <td>What is the baseline method for the task?</td>\n",
       "      <td>1909.02764</td>\n",
       "      <td>For the emotion recognition from text they use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ef9cc1d1d60f875969094bb246be529373cb1d</td>\n",
       "      <td>What methodology is used to compensate for lim...</td>\n",
       "      <td>1904.07342</td>\n",
       "      <td>Influential tweeters ( who they define as indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01123a39574bdc4684aafa59c52d956b532d2e53</td>\n",
       "      <td>By how much does their method outperform state...</td>\n",
       "      <td>1905.10247</td>\n",
       "      <td>AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01dc6893fc2f49b732449dfe1907505e747440b0</td>\n",
       "      <td>What debate topics are included in the dataset?</td>\n",
       "      <td>1906.03538</td>\n",
       "      <td>Ethics, Gender, Human rights, Sports, Freedom ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question_id  \\\n",
       "0  0038b073b7cca847033177024f9719c971692042   \n",
       "1  00bcdffff7e055f99aaf1b05cf41c98e2748e948   \n",
       "2  00ef9cc1d1d60f875969094bb246be529373cb1d   \n",
       "3  01123a39574bdc4684aafa59c52d956b532d2e53   \n",
       "4  01dc6893fc2f49b732449dfe1907505e747440b0   \n",
       "\n",
       "                                            question    paper_id  \\\n",
       "0  How is the input triple translated to a slot-f...  1706.04115   \n",
       "1          What is the baseline method for the task?  1909.02764   \n",
       "2  What methodology is used to compensate for lim...  1904.07342   \n",
       "3  By how much does their method outperform state...  1905.10247   \n",
       "4    What debate topics are included in the dataset?  1906.03538   \n",
       "\n",
       "                                    free_form_answer  \n",
       "0  The relation R(x,y) is mapped onto a question ...  \n",
       "1  For the emotion recognition from text they use...  \n",
       "2  Influential tweeters ( who they define as indi...  \n",
       "3  AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...  \n",
       "4  Ethics, Gender, Human rights, Sports, Freedom ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20368b84-2559-4739-b6e9-366bd22f007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb3c7a1-75ef-4557-919b-498398bfab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(question, paper_id=None, k=10):\n",
    "    where_clause = {\"paper_id\": str(paper_id)} if paper_id else None\n",
    "\n",
    "    result = chroma_collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=k,\n",
    "        where=where_clause\n",
    "    )\n",
    "    \n",
    "    pairs = [(question, doc) for doc in result[\"documents\"][0]]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    # sort by score descending\n",
    "    reranked = [doc for _, doc in sorted(zip(scores, result[\"documents\"][0]), key=lambda x: x[0], reverse=True)]\n",
    "    final_chunks = reranked[:3]\n",
    "\n",
    "    context_text = \" \".join(final_chunks)\n",
    "\n",
    "    \n",
    "    context_text = \" \".join(result[\"documents\"][0])  # combine list of strings into one\n",
    "    clean_chunk = re.sub(r\"\\$.*?\\$\", \"\", context_text)   # remove inline math\n",
    " \n",
    "    # Return list of text chunks\n",
    "    return clean_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e8830a-5aac-4c08-8248-856cb107b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "QA_MODEL = \"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(QA_MODEL)\n",
    "qa_model     = AutoModelForQuestionAnswering.from_pretrained(QA_MODEL)\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5210a1-fd60-478a-a13d-9b8b2e0fc052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_with_confidence(question, context):\n",
    "    inputs = qa_tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = qa_model(**inputs)\n",
    "\n",
    "    start_idx = outputs.start_logits.argmax()\n",
    "    end_idx   = outputs.end_logits.argmax()\n",
    "\n",
    "    answer_tokens = inputs.input_ids[0, start_idx:end_idx+1]\n",
    "    decoded_answer = qa_tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    start_probs = F.softmax(outputs.start_logits, dim=-1)\n",
    "    end_probs   = F.softmax(outputs.end_logits, dim=-1)\n",
    "    confidence  = (start_probs[0, start_idx] * end_probs[0, end_idx]).item()\n",
    "\n",
    "    return decoded_answer, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a66f471-6aed-4d9a-923b-e23a68b670dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(prediction, ground_truth):\n",
    "    emb_pred = embedder.encode(prediction, convert_to_tensor=True)\n",
    "    emb_gt   = embedder.encode(ground_truth, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb_pred, emb_gt).item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69252a79-eba4-4006-9814-c8fdef080318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 01edeca7b902ae3fd66264366bf548acea1db364 (no context retrieved)\n",
      "Skipping 0b54032508c96ff3320c3db613aeb25d42d00490 (no context retrieved)\n",
      "Skipping 0bd683c51a87a110b68b377e9a06f0a3e12c8da0 (no context retrieved)\n",
      "Skipping 11dde2be9a69a025f2fc29ce647201fb5a4df580 (no context retrieved)\n",
      "Skipping 144714fe0d5a2bb7e21a7bf50df39d790ff12916 (no context retrieved)\n",
      "Skipping 18fbf9c08075e3b696237d22473c463237d153f5 (no context retrieved)\n",
      "Skipping 255fb6e20b95092c548ba47d8a295468e06698bd (no context retrieved)\n",
      "Skipping 25e4dbc7e211a1ebe02ee8dff675b846fb18fdc5 (no context retrieved)\n",
      "Skipping 271019168ed3a2b0ef5e3780b48a1ebefc562b57 (no context retrieved)\n",
      "Skipping 2a1e6a69e06da2328fc73016ee057378821e0754 (no context retrieved)\n",
      "Skipping 2d3bf170c1647c5a95abae50ee3ef3b404230ce4 (no context retrieved)\n",
      "Skipping 2d47cdf2c1e0c64c73518aead1b94e0ee594b7a5 (no context retrieved)\n",
      "Skipping 2fa0b9d0cb26e1be8eae7e782ada6820bc2c037f (no context retrieved)\n",
      "Skipping 37753fbffc06ce7de6ada80c89f1bf5f190bbd88 (no context retrieved)\n",
      "Skipping 37e8f5851133a748c4e3e0beeef0d83883117a98 (no context retrieved)\n",
      "Skipping 39c78924df095c92e058ffa5a779de597e8c43f4 (no context retrieved)\n",
      "Skipping 3c362bfa11c60bad6c7ea83f8753d427cda77de0 (no context retrieved)\n",
      "Skipping 4059c6f395640a6acf20a0ed451d0ad8681bc59b (no context retrieved)\n",
      "Skipping 44104668796a6ca10e2ea3ecf706541da1cec2cf (no context retrieved)\n",
      "Skipping 458dbf217218fcab9153e33045aac08a2c8a38c6 (no context retrieved)\n",
      "Skipping 4d05a264b2353cff310edb480a917d686353b007 (no context retrieved)\n",
      "Skipping 5a29b1f9181f5809e2b0f97b4d0e00aea8996892 (no context retrieved)\n",
      "Skipping 5a9f94ae296dda06c8aec0fb389ce2f68940ea88 (no context retrieved)\n",
      "Skipping 5d6cc65b73f428ea2a499bcf91995ef5441f63d4 (no context retrieved)\n",
      "Skipping 5dc1aca619323ea0d4717d1f825606b2b7c21f01 (no context retrieved)\n",
      "Skipping 5f7850254b723adf891930c6faced1058b99bd57 (no context retrieved)\n",
      "Skipping 6270d5247f788c4627be57de6cf30112560c863f (no context retrieved)\n",
      "Skipping 68ff2a14e6f0e115ef12c213cf852a35a4d73863 (no context retrieved)\n",
      "Skipping 6e8c587b6562fafb43a7823637b84cd01487059a (no context retrieved)\n",
      "Skipping 6ea63327ffbab2fc734dd5c2414e59d3acc56ea5 (no context retrieved)\n",
      "Skipping 73bbe0b6457423f08d9297a0951381098bd89a2b (no context retrieved)\n",
      "Skipping 7b2bf0c1a24a2aa01d49f3c7e1bdc7401162c116 (no context retrieved)\n",
      "Skipping 7ee29d657ccb8eb9d5ec64d4afc3ca8b5f3bcc9f (no context retrieved)\n",
      "Skipping 858c51842fc3c1f3e6d2d7d853c94f6de27afade (no context retrieved)\n",
      "Skipping 85912b87b16b45cde79039447a70bd1f6f1f8361 (no context retrieved)\n",
      "Skipping 8cc56fc44136498471754186cfa04056017b4e54 (no context retrieved)\n",
      "Skipping 955ca31999309685c1daa5cb03867971ca99ec52 (no context retrieved)\n",
      "Skipping 9776156fc93daa36f4613df591e2b49827d25ad2 (no context retrieved)\n",
      "Skipping 99c50d51a428db09edaca0d07f4dab0503af1b94 (no context retrieved)\n",
      "Skipping a1557ec0f3deb1e4cd1e68f4880dcecda55656dd (no context retrieved)\n",
      "Skipping a25c1883f0a99d2b6471fed48c5121baccbbae82 (no context retrieved)\n",
      "Skipping a7510ec34eaec2c7ac2869962b69cc41031221e5 (no context retrieved)\n",
      "Skipping a979749e59e6e300a453d8a8b1627f97101799de (no context retrieved)\n",
      "Skipping a996b6aee9be88a3db3f4127f9f77a18ed10caba (no context retrieved)\n",
      "Skipping ab9453fa2b927c97b60b06aeda944ac5c1bfef1e (no context retrieved)\n",
      "Skipping b0376a7f67f1568a7926eff8ff557a93f434a253 (no context retrieved)\n",
      "Skipping b6b5f92a1d9fa623b25c70c1ac67d59d84d9eec8 (no context retrieved)\n",
      "Skipping ba6422e22297c7eb0baa381225a2f146b9621791 (no context retrieved)\n",
      "Skipping c33d0bc5484c38de0119c8738ffa985d1bd64424 (no context retrieved)\n",
      "Skipping c4a6b727769328333bb48d59d3fc4036a084875d (no context retrieved)\n",
      "Skipping cebf3e07057339047326cb2f8863ee633a62f49f (no context retrieved)\n",
      "Skipping cf63a4f9fe0f71779cf5a014807ae4528279c25a (no context retrieved)\n",
      "Skipping d05d667822cb49cefd03c24a97721f1fe9dc0f4c (no context retrieved)\n",
      "Skipping da845a2a930fd6a3267950bec5928205b6c6e8e8 (no context retrieved)\n",
      "Skipping dd5c9a370652f6550b4fd13e2ac317eaf90973a8 (no context retrieved)\n",
      "Skipping e286860c41a4f704a3a08e45183cb8b14fa2ad2f (no context retrieved)\n",
      "Skipping e42fbf6c183abf1c6c2321957359c7683122b48e (no context retrieved)\n",
      "Skipping e8029ec69b0b273954b4249873a5070c2a0edb8a (no context retrieved)\n",
      "Skipping f258ada8577bb71873581820a94695f4a2c223b3 (no context retrieved)\n",
      "Skipping f37ed011e7eb259360170de027c1e8557371f002 (no context retrieved)\n",
      "Skipping f5db12cd0a8cd706a232c69d94b2258596aa068c (no context retrieved)\n",
      "Skipping f8281eb49be3e8ea0af735ad3bec955a5dedf5b3 (no context retrieved)\n",
      "Skipping fa9df782d743ce0ce1a7a5de6a3de226a7e423df (no context retrieved)\n",
      "Average Confidence : 0.1641913890329095\n",
      "Average Cosine Sim : 0.24691531400363284\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _, row in questions.iterrows():\n",
    "    chunks = retrieve_chunks(row.question, row.paper_id)\n",
    "    \n",
    "    if not chunks or chunks.strip() == \"\":\n",
    "        print(f\"Skipping {row.question_id} (no context retrieved)\")\n",
    "        continue\n",
    "    \n",
    "    pred, conf = qa_with_confidence(row.question, chunks)\n",
    "    cos        = cosine_similarity(pred, str(row.free_form_answer))\n",
    "    results.append({\n",
    "        \"question_id\": row.question_id,\n",
    "        \"question\" : row.question,\n",
    "        \"model_answer\": pred,\n",
    "        \"ground_truth\": str(row.free_form_answer),\n",
    "        \"confidence\": conf,\n",
    "        \"cosine_sim\": cos\n",
    "    })\n",
    "\n",
    "scores_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Average Confidence :\", scores_df[\"confidence\"].mean())\n",
    "print(\"Average Cosine Sim :\", scores_df[\"cosine_sim\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d6408-e2b3-4d6a-bde3-de54acb77fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa0fabed-d405-476b-b373-4b796cf5320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# print(\"Starting download and caching of Hugging Face models...\")\n",
    "\n",
    "# QA_MODELS = [\n",
    "#       \"deepset/tinyroberta-squad2\",\n",
    "#       \"deepset/roberta-base-squad2\",\n",
    "#       \"google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "# ]\n",
    "\n",
    "# for model_name in QA_MODELS:\n",
    "#     try:\n",
    "#         # print(f\"Loading model: {model_name}\")\n",
    "#         # Load tokenizer\n",
    "#         tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "#         # This is the essential part for downloading and caching the model\n",
    "#         model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "        \n",
    "#         # The following lines simulate a quick inference to ensure everything is loaded correctly\n",
    "#         question = \"How many programming languages does BLOOM support?\"\n",
    "#         context = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\"\n",
    "#         inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "\n",
    "#         answer_start_index = outputs.start_logits.argmax()\n",
    "#         answer_end_index = outputs.end_logits.argmax()\n",
    "#         predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "#         decoded_answer = tokenizer.decode(predict_answer_tokens)\n",
    "        \n",
    "#         print(f\"Successfully loaded and tested: {model_name}. Predicted answer: '{decoded_answer}'\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to load model {model_name}. Error: {e}\")\n",
    "\n",
    "# print(\"Model loading process complete.\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56039ee7-ed19-487a-bb4d-94e72d3924b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
