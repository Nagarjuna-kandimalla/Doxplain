{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab5180e-e79e-4680-b953-8be7fa87b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub in /home/dswdfb/.local/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /home/dswdfb/.local/lib/python3.11/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/dswdfb/.local/lib/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/dswdfb/.local/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->kagglehub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->kagglehub) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553493eb-d631-49e1-a836-83b417d4f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/dswdfb/.local/lib/python3.11/site-packages (4.56.2)\n",
      "Requirement already satisfied: datasets in /home/dswdfb/.local/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: sentence-transformers in /home/dswdfb/.local/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: langchain in /home/dswdfb/.local/lib/python3.11/site-packages (0.3.18)\n",
      "Requirement already satisfied: chromadb in /home/dswdfb/.local/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: filelock in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/dswdfb/.local/lib/python3.11/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: Pillow in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.75.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.19.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from chromadb) (4.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in /home/dswdfb/.local/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /home/dswdfb/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dswdfb/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/dswdfb/.local/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
      "Requirement already satisfied: protobuf in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/dswdfb/.local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/dswdfb/.local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dswdfb/.local/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/dswdfb/.local/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/dswdfb/.local/lib/python3.11/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/dswdfb/.local/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dswdfb/.local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.3\n",
      "    Uninstalling numpy-2.3.3:\n",
      "      Successfully uninstalled numpy-2.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\n",
      "fuzzy-c-means 1.7.2 requires typer<0.10.0,>=0.9.0, but you have typer 0.19.2 which is incompatible.\n",
      "en-core-sci-md 0.5.0 requires spacy<3.3.0,>=3.2.3, but you have spacy 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets sentence-transformers langchain chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009d5fe1-082e-4560-bce7-e463ed4f9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/dswdfb/.local/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (4.56.2)\n",
      "Requirement already satisfied: tqdm in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (0.35.1)\n",
      "Requirement already satisfied: Pillow in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d363aec3-ad50-4345-95e7-40ad2aa1b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy>=2.0\n",
      "  Using cached numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: scipy>=1.14 in /home/dswdfb/.local/lib/python3.11/site-packages (1.16.2)\n",
      "Requirement already satisfied: scikit-learn in /home/dswdfb/.local/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: transformers in /home/dswdfb/.local/lib/python3.11/site-packages (4.56.2)\n",
      "Requirement already satisfied: sentence-transformers in /home/dswdfb/.local/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: chromadb in /home/dswdfb/.local/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dswdfb/.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: Pillow in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (1.75.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.19.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (32.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from chromadb) (4.19.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/dswdfb/.local/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /home/dswdfb/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dswdfb/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/dswdfb/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
      "Requirement already satisfied: protobuf in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /home/dswdfb/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/dswdfb/.local/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/dswdfb/.local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/dswdfb/.local/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: networkx in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/dswdfb/.local/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dswdfb/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/dswdfb/.local/lib/python3.11/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /cluster/software/conda-envs-global/jupyter/envs/jupytern_706/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/dswdfb/.local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dswdfb/.local/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dswdfb/.local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Using cached numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.3.3 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.3 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
      "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\n",
      "fuzzy-c-means 1.7.2 requires numpy<2.0.0,>=1.21.1, but you have numpy 2.3.3 which is incompatible.\n",
      "fuzzy-c-means 1.7.2 requires typer<0.10.0,>=0.9.0, but you have typer 0.19.2 which is incompatible.\n",
      "en-core-sci-md 0.5.0 requires spacy<3.3.0,>=3.2.3, but you have spacy 3.8.4 which is incompatible.\n",
      "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"numpy>=2.0\" \"scipy>=1.14\" scikit-learn transformers sentence-transformers chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61461e13-e6df-4587-a6e8-28819f99e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3325c9ce-0cc8-481b-be62-70766808f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import ast \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "809e7323-7e3b-44c3-b746-d4b909056184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8545e35c-a075-4668-8df7-1dbc0ab9181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to QASPER dataset: /home/dswdfb/.cache/kagglehub/datasets/thedevastator/qasper-nlp-questions-and-evidence/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Download QASPER dataset using KaggleHub\n",
    "dataset_path = kagglehub.dataset_download(\"thedevastator/qasper-nlp-questions-and-evidence\")\n",
    "print(f\"Path to QASPER dataset: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6de17e14-3b82-4fb8-91bc-d138489d3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing QASPER dataset\n",
    "\n",
    "\n",
    "test = pd.read_csv(f\"{dataset_path}/test.csv\")\n",
    "train = pd.read_csv(f\"{dataset_path}/train.csv\")\n",
    "validation = pd.read_csv(f\"{dataset_path}/validation.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5f54c-9674-46b2-acf6-d0acde68d6e5",
   "metadata": {},
   "source": [
    "We had issues with the Keggle CSV file for QASPER DATASET. Tried parsing it manually as well as using the nested objects, but it still gave errors. This may be because of the object is converted to a string and the string contains Object types like 'Array()' which cause the json parse error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac752cd-5d1b-4d53-8d31-50697690519f",
   "metadata": {},
   "source": [
    "We are using the same data QASPER sets but via HuggingFace, which provides straightfaward json object to parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68f648-f3a8-4e1f-88b8-64967f501b59",
   "metadata": {},
   "source": [
    "### Load the QASPER from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf51b14f-806e-423a-b2e3-5294f9fb9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "qasper_ds = load_dataset(\"allenai/qasper\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33823591-f81e-4cb3-b93a-ec9d90798383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'abstract', 'full_text', 'qas', 'figures_and_tables'],\n",
       "    num_rows: 888\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasper_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08f5fa59-9fc9-45af-9a76-413eb8d90d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for paper in qasper_ds:\n",
    "    paper_id = paper[\"id\"]\n",
    "    title    = paper[\"title\"]\n",
    "    abstract = paper[\"abstract\"]\n",
    "\n",
    "    # full_text is a dict of columns\n",
    "    sec_names = paper[\"full_text\"][\"section_name\"]\n",
    "    sec_paras = paper[\"full_text\"][\"paragraphs\"]\n",
    "    full_text = \"\\n\\n\".join(\n",
    "        f\"{sec}\\n\" + \"\\n\".join(p) for sec, p in zip(sec_names, sec_paras)\n",
    "    )\n",
    "\n",
    "    qas = paper[\"qas\"]\n",
    "    n_questions = len(qas[\"question\"])\n",
    "\n",
    "    for i in range(n_questions):\n",
    "        question_id   = qas[\"question_id\"][i]\n",
    "        question_text = qas[\"question\"][i]\n",
    "        nlp_bg        = qas[\"nlp_background\"][i]\n",
    "        topic_bg      = qas[\"topic_background\"][i]\n",
    "        paper_read    = qas[\"paper_read\"][i]\n",
    "        search_query  = qas[\"search_query\"][i]\n",
    "        question_writer = qas[\"question_writer\"][i]\n",
    "\n",
    "        # answers is ALSO a dict of parallel lists\n",
    "        answers_block = qas[\"answers\"][i]\n",
    "        for ans, ann_id, worker_id in zip(\n",
    "            answers_block[\"answer\"],\n",
    "            answers_block[\"annotation_id\"],\n",
    "            answers_block[\"worker_id\"]\n",
    "        ):\n",
    "            rows.append({\n",
    "                \"paper_id\"        : paper_id,\n",
    "                \"title\"           : title,\n",
    "                \"abstract\"        : abstract,\n",
    "                \"full_text\"       : full_text,\n",
    "                \"question_id\"     : question_id,\n",
    "                \"question\"        : question_text,\n",
    "                \"nlp_background\"  : nlp_bg,\n",
    "                \"topic_background\": topic_bg,\n",
    "                \"paper_read\"      : paper_read,\n",
    "                \"search_query\"    : search_query,\n",
    "                \"question_writer\" : question_writer,\n",
    "                \"annotation_id\"   : ann_id,\n",
    "                \"worker_id\"       : worker_id,\n",
    "                \"unanswerable\"    : ans[\"unanswerable\"],\n",
    "                \"yes_no\"          : ans[\"yes_no\"],\n",
    "                \"free_form_answer\": ans[\"free_form_answer\"],\n",
    "                \"extractive_spans\": \"; \".join(ans[\"extractive_spans\"]),\n",
    "                \"evidence\"        : \"; \".join(ans[\"evidence\"]),\n",
    "                \"highlighted_evidence\": \"; \".join(ans[\"highlighted_evidence\"])\n",
    "            })\n",
    "\n",
    "qasper_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bd21744-7b64-4bf6-96b2-baf23c4c1b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>nlp_background</th>\n",
       "      <th>topic_background</th>\n",
       "      <th>paper_read</th>\n",
       "      <th>search_query</th>\n",
       "      <th>question_writer</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>unanswerable</th>\n",
       "      <th>yes_no</th>\n",
       "      <th>free_form_answer</th>\n",
       "      <th>extractive_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>highlighted_evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>753990d0b621d390ed58f20c4d9e4f065f0dc672</td>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>31e85022a847f37c15fd0415f3c450c74c8e4755</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>a vocabulary of positive and negative predicat...</td>\n",
       "      <td></td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>753990d0b621d390ed58f20c4d9e4f065f0dc672</td>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>95da0a6e1b08db74a405c6a71067c9b272a50ff5</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>seed lexicon consists of positive and negative...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>9d578ddccc27dd849244d632dd0f6bf27348ad81</td>\n",
       "      <td>What are the results?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>1e5e867244ea656c4b7632628086209cf9bae5fa</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td></td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>49a78a07d2eed545556a835ccf2eb40e5eee9801</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>based on the relation between events, the sugg...</td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>cause relation: both events in the relation sh...</td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "1  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "2  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "3  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "4  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Recognizing affective events that trigger posi...   \n",
       "1  Recognizing affective events that trigger posi...   \n",
       "2  Recognizing affective events that trigger posi...   \n",
       "3  Recognizing affective events that trigger posi...   \n",
       "4  Recognizing affective events that trigger posi...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "1  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "2  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "3  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "4  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "\n",
       "                                question_id  \\\n",
       "0  753990d0b621d390ed58f20c4d9e4f065f0dc672   \n",
       "1  753990d0b621d390ed58f20c4d9e4f065f0dc672   \n",
       "2  9d578ddccc27dd849244d632dd0f6bf27348ad81   \n",
       "3  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "4  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "\n",
       "                                        question nlp_background  \\\n",
       "0                      What is the seed lexicon?            two   \n",
       "1                      What is the seed lexicon?            two   \n",
       "2                          What are the results?            two   \n",
       "3  How are relations used to propagate polarity?            two   \n",
       "4  How are relations used to propagate polarity?            two   \n",
       "\n",
       "  topic_background paper_read search_query  \\\n",
       "0       unfamiliar         no                \n",
       "1       unfamiliar         no                \n",
       "2       unfamiliar         no                \n",
       "3       unfamiliar         no                \n",
       "4       unfamiliar         no                \n",
       "\n",
       "                            question_writer  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "1  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "2  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "3  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "4  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "\n",
       "                              annotation_id  \\\n",
       "0  31e85022a847f37c15fd0415f3c450c74c8e4755   \n",
       "1  95da0a6e1b08db74a405c6a71067c9b272a50ff5   \n",
       "2  1e5e867244ea656c4b7632628086209cf9bae5fa   \n",
       "3  49a78a07d2eed545556a835ccf2eb40e5eee9801   \n",
       "4  acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1   \n",
       "\n",
       "                                  worker_id  unanswerable yes_no  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False   None   \n",
       "1  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "2  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "3  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False   None   \n",
       "4  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "\n",
       "                                    free_form_answer  \\\n",
       "0  a vocabulary of positive and negative predicat...   \n",
       "1                                                      \n",
       "2  Using all data to train: AL -- BiGRU achieved ...   \n",
       "3  based on the relation between events, the sugg...   \n",
       "4  cause relation: both events in the relation sh...   \n",
       "\n",
       "                                    extractive_spans  \\\n",
       "0                                                      \n",
       "1  seed lexicon consists of positive and negative...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                            evidence  \\\n",
       "0  The seed lexicon consists of positive and nega...   \n",
       "1  The seed lexicon consists of positive and nega...   \n",
       "2  FLOAT SELECTED: Table 3: Performance of variou...   \n",
       "3  In this paper, we propose a simple and effecti...   \n",
       "4  In this paper, we propose a simple and effecti...   \n",
       "\n",
       "                                highlighted_evidence  \n",
       "0  The seed lexicon consists of positive and nega...  \n",
       "1  The seed lexicon consists of positive and nega...  \n",
       "2  FLOAT SELECTED: Table 3: Performance of variou...  \n",
       "3  As illustrated in Figure FIGREF1, our key idea...  \n",
       "4  As illustrated in Figure FIGREF1, our key idea...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c6b5df-635f-4fc7-9bde-405c1ff3504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qasper_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba17c08c-d16a-49e5-9958-b33912ad9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop question rows where the answer is empty\n",
    "qasper_df = qasper_df[qasper_df['free_form_answer'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e02724e8-5a7c-46c6-9b14-a958b4b81315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qasper_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97cf70e8-5f40-454e-a678-a4b516e974a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>nlp_background</th>\n",
       "      <th>topic_background</th>\n",
       "      <th>paper_read</th>\n",
       "      <th>search_query</th>\n",
       "      <th>question_writer</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>unanswerable</th>\n",
       "      <th>yes_no</th>\n",
       "      <th>free_form_answer</th>\n",
       "      <th>extractive_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>highlighted_evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>753990d0b621d390ed58f20c4d9e4f065f0dc672</td>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>31e85022a847f37c15fd0415f3c450c74c8e4755</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>a vocabulary of positive and negative predicat...</td>\n",
       "      <td></td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>9d578ddccc27dd849244d632dd0f6bf27348ad81</td>\n",
       "      <td>What are the results?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>1e5e867244ea656c4b7632628086209cf9bae5fa</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td></td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>49a78a07d2eed545556a835ccf2eb40e5eee9801</td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>based on the relation between events, the sugg...</td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>02e4bf719b1a504e385c35c6186742e720bcb281</td>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>cause relation: both events in the relation sh...</td>\n",
       "      <td></td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>As illustrated in Figure FIGREF1, our key idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1909.00694</td>\n",
       "      <td>Minimally Supervised Learning of Affective Eve...</td>\n",
       "      <td>Recognizing affective events that trigger posi...</td>\n",
       "      <td>Introduction\\nAffective events BIBREF0 are eve...</td>\n",
       "      <td>44c4bd6decc86f1091b5fc0728873d9324cdde4e</td>\n",
       "      <td>How big is the Japanese data?</td>\n",
       "      <td>two</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td>c1fbdd7a261021041f75fbe00a55b4c386ebbbb4</td>\n",
       "      <td>36926a4c9e14352c91111150aa4c6edcc5c0770f</td>\n",
       "      <td>2cfd959e433f290bb50b55722370f0d22fe090b7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7000000 pairs of events were extracted from th...</td>\n",
       "      <td></td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "2  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "3  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "4  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "5  1909.00694  Minimally Supervised Learning of Affective Eve...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Recognizing affective events that trigger posi...   \n",
       "2  Recognizing affective events that trigger posi...   \n",
       "3  Recognizing affective events that trigger posi...   \n",
       "4  Recognizing affective events that trigger posi...   \n",
       "5  Recognizing affective events that trigger posi...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "2  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "3  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "4  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "5  Introduction\\nAffective events BIBREF0 are eve...   \n",
       "\n",
       "                                question_id  \\\n",
       "0  753990d0b621d390ed58f20c4d9e4f065f0dc672   \n",
       "2  9d578ddccc27dd849244d632dd0f6bf27348ad81   \n",
       "3  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "4  02e4bf719b1a504e385c35c6186742e720bcb281   \n",
       "5  44c4bd6decc86f1091b5fc0728873d9324cdde4e   \n",
       "\n",
       "                                        question nlp_background  \\\n",
       "0                      What is the seed lexicon?            two   \n",
       "2                          What are the results?            two   \n",
       "3  How are relations used to propagate polarity?            two   \n",
       "4  How are relations used to propagate polarity?            two   \n",
       "5                  How big is the Japanese data?            two   \n",
       "\n",
       "  topic_background paper_read search_query  \\\n",
       "0       unfamiliar         no                \n",
       "2       unfamiliar         no                \n",
       "3       unfamiliar         no                \n",
       "4       unfamiliar         no                \n",
       "5       unfamiliar         no                \n",
       "\n",
       "                            question_writer  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "2  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "3  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "4  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "5  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4   \n",
       "\n",
       "                              annotation_id  \\\n",
       "0  31e85022a847f37c15fd0415f3c450c74c8e4755   \n",
       "2  1e5e867244ea656c4b7632628086209cf9bae5fa   \n",
       "3  49a78a07d2eed545556a835ccf2eb40e5eee9801   \n",
       "4  acd6d15bd67f4b1496ee8af1c93c33e7d59c89e1   \n",
       "5  36926a4c9e14352c91111150aa4c6edcc5c0770f   \n",
       "\n",
       "                                  worker_id  unanswerable yes_no  \\\n",
       "0  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False   None   \n",
       "2  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "3  c1fbdd7a261021041f75fbe00a55b4c386ebbbb4         False   None   \n",
       "4  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "5  2cfd959e433f290bb50b55722370f0d22fe090b7         False   None   \n",
       "\n",
       "                                    free_form_answer extractive_spans  \\\n",
       "0  a vocabulary of positive and negative predicat...                    \n",
       "2  Using all data to train: AL -- BiGRU achieved ...                    \n",
       "3  based on the relation between events, the sugg...                    \n",
       "4  cause relation: both events in the relation sh...                    \n",
       "5  7000000 pairs of events were extracted from th...                    \n",
       "\n",
       "                                            evidence  \\\n",
       "0  The seed lexicon consists of positive and nega...   \n",
       "2  FLOAT SELECTED: Table 3: Performance of variou...   \n",
       "3  In this paper, we propose a simple and effecti...   \n",
       "4  In this paper, we propose a simple and effecti...   \n",
       "5  As a raw corpus, we used a Japanese web corpus...   \n",
       "\n",
       "                                highlighted_evidence  \n",
       "0  The seed lexicon consists of positive and nega...  \n",
       "2  FLOAT SELECTED: Table 3: Performance of variou...  \n",
       "3  As illustrated in Figure FIGREF1, our key idea...  \n",
       "4  As illustrated in Figure FIGREF1, our key idea...  \n",
       "5  As a raw corpus, we used a Japanese web corpus...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6413f940-ad6e-46a4-b757-1ef0efbba466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0038b073b7cca847033177024f9719c971692042</td>\n",
       "      <td>How is the input triple translated to a slot-f...</td>\n",
       "      <td>1706.04115</td>\n",
       "      <td>The relation R(x,y) is mapped onto a question ...</td>\n",
       "      <td>We show that it is possible to reduce relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00bcdffff7e055f99aaf1b05cf41c98e2748e948</td>\n",
       "      <td>What is the baseline method for the task?</td>\n",
       "      <td>1909.02764</td>\n",
       "      <td>For the emotion recognition from text they use...</td>\n",
       "      <td>For the emotion recognition from text, we manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ef9cc1d1d60f875969094bb246be529373cb1d</td>\n",
       "      <td>What methodology is used to compensate for lim...</td>\n",
       "      <td>1904.07342</td>\n",
       "      <td>Influential tweeters ( who they define as indi...</td>\n",
       "      <td>The first data batch consists of tweets releva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01123a39574bdc4684aafa59c52d956b532d2e53</td>\n",
       "      <td>By how much does their method outperform state...</td>\n",
       "      <td>1905.10247</td>\n",
       "      <td>AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...</td>\n",
       "      <td>The goal of this paper is to propose a novel O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01dc6893fc2f49b732449dfe1907505e747440b0</td>\n",
       "      <td>What debate topics are included in the dataset?</td>\n",
       "      <td>1906.03538</td>\n",
       "      <td>Ethics, Gender, Human rights, Sports, Freedom ...</td>\n",
       "      <td>FLOAT SELECTED: Figure 3: Distribution of clai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  0038b073b7cca847033177024f9719c971692042   \n",
       "1  00bcdffff7e055f99aaf1b05cf41c98e2748e948   \n",
       "2  00ef9cc1d1d60f875969094bb246be529373cb1d   \n",
       "3  01123a39574bdc4684aafa59c52d956b532d2e53   \n",
       "4  01dc6893fc2f49b732449dfe1907505e747440b0   \n",
       "\n",
       "                                            question    paper_id  \\\n",
       "0  How is the input triple translated to a slot-f...  1706.04115   \n",
       "1          What is the baseline method for the task?  1909.02764   \n",
       "2  What methodology is used to compensate for lim...  1904.07342   \n",
       "3  By how much does their method outperform state...  1905.10247   \n",
       "4    What debate topics are included in the dataset?  1906.03538   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The relation R(x,y) is mapped onto a question ...   \n",
       "1  For the emotion recognition from text they use...   \n",
       "2  Influential tweeters ( who they define as indi...   \n",
       "3  AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...   \n",
       "4  Ethics, Gender, Human rights, Sports, Freedom ...   \n",
       "\n",
       "                                             context  \n",
       "0  We show that it is possible to reduce relation...  \n",
       "1  For the emotion recognition from text, we manu...  \n",
       "2  The first data batch consists of tweets releva...  \n",
       "3  The goal of this paper is to propose a novel O...  \n",
       "4  FLOAT SELECTED: Figure 3: Distribution of clai...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only rows with a question\n",
    "questions = (\n",
    "    qasper_df.groupby(\"question_id\")\n",
    "        .first()\n",
    "        .reset_index()[[\"question_id\", \"question\", \"paper_id\", \"free_form_answer\", \"evidence\"]]\n",
    "        .rename(columns={\n",
    "            \"question_id\": \"id\",\n",
    "            \"free_form_answer\": \"answer\",\n",
    "            \"evidence\": \"context\"\n",
    "\n",
    "        })\n",
    ")\n",
    "\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "025c326a-beb4-4c3c-b29c-202f96bf20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.to_csv('processed_qasper_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645a0bf-8e2c-4346-8c37-3982f8548702",
   "metadata": {},
   "source": [
    "### Loading the HotPotQA Dataset from Kegglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd5c58cb-976d-4ef6-8497-99c481cf9339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to HotpotQA dataset: /home/dswdfb/.cache/kagglehub/datasets/jeromeblanchet/hotpotqa-question-answering-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download HotpotQA dataset using KaggleHub\n",
    "path = kagglehub.dataset_download(\"jeromeblanchet/hotpotqa-question-answering-dataset\")\n",
    "print(f\"Path to HotpotQA dataset: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1209d513-d3db-4625-a765-1581caa9bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7405\n",
      "dict_keys(['_id', 'answer', 'question', 'supporting_facts', 'context', 'type', 'level'])\n"
     ]
    }
   ],
   "source": [
    "#Importing HotPotQA Dataset\n",
    "import json\n",
    "\n",
    "with open(f\"{path}/hotpot_dev_distractor_v1.json\", \"r\") as f:\n",
    "    hotpot_data = json.load(f)\n",
    "\n",
    "print(len(hotpot_data))        \n",
    "print(hotpot_data[0].keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ce115bd-5ba2-4e95-815f-533470bfc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for ex in hotpot_data:\n",
    "    rows.append({\n",
    "        \"id\": ex[\"_id\"],\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"answer\": ex[\"answer\"],\n",
    "        \"context\": ex[\"context\"],\n",
    "        \"supporting_facts\": ex[\"supporting_facts\"]\n",
    "    })\n",
    "\n",
    "hotpot_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f76473b-c192-4ff3-9bca-c4a8d0b7c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>supporting_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[[Ed Wood (film), [Ed Wood is a 1994 American ...</td>\n",
       "      <td>[[Scott Derrickson, 0], [Ed Wood, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>What government position was held by the woman...</td>\n",
       "      <td>Chief of Protocol</td>\n",
       "      <td>[[Meet Corliss Archer, [Meet Corliss Archer, a...</td>\n",
       "      <td>[[Kiss and Tell (1945 film), 0], [Shirley Temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>What science fantasy young adult series, told ...</td>\n",
       "      <td>Animorphs</td>\n",
       "      <td>[[Andre Norton Award, [The Andre Norton Award ...</td>\n",
       "      <td>[[The Hork-Bajir Chronicles, 0], [The Hork-Baj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adbf0a255429947ff17385a</td>\n",
       "      <td>Are the Laleli Mosque and Esma Sultan Mansion ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[[Esma Sultan (daughter of Abdülaziz), [Esma S...</td>\n",
       "      <td>[[Laleli Mosque, 0], [Esma Sultan Mansion, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a8e3ea95542995a26add48d</td>\n",
       "      <td>The director of the romantic comedy \"Big Stone...</td>\n",
       "      <td>Greenwich Village, New York City</td>\n",
       "      <td>[[Just Another Romantic Wrestling Comedy, [Jus...</td>\n",
       "      <td>[[Big Stone Gap (film), 0], [Adriana Trigiani,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5a8b57f25542995d1e6f1371   \n",
       "1  5a8c7595554299585d9e36b6   \n",
       "2  5a85ea095542994775f606a8   \n",
       "3  5adbf0a255429947ff17385a   \n",
       "4  5a8e3ea95542995a26add48d   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "1  What government position was held by the woman...   \n",
       "2  What science fantasy young adult series, told ...   \n",
       "3  Are the Laleli Mosque and Esma Sultan Mansion ...   \n",
       "4  The director of the romantic comedy \"Big Stone...   \n",
       "\n",
       "                             answer  \\\n",
       "0                               yes   \n",
       "1                 Chief of Protocol   \n",
       "2                         Animorphs   \n",
       "3                                no   \n",
       "4  Greenwich Village, New York City   \n",
       "\n",
       "                                             context  \\\n",
       "0  [[Ed Wood (film), [Ed Wood is a 1994 American ...   \n",
       "1  [[Meet Corliss Archer, [Meet Corliss Archer, a...   \n",
       "2  [[Andre Norton Award, [The Andre Norton Award ...   \n",
       "3  [[Esma Sultan (daughter of Abdülaziz), [Esma S...   \n",
       "4  [[Just Another Romantic Wrestling Comedy, [Jus...   \n",
       "\n",
       "                                    supporting_facts  \n",
       "0              [[Scott Derrickson, 0], [Ed Wood, 0]]  \n",
       "1  [[Kiss and Tell (1945 film), 0], [Shirley Temp...  \n",
       "2  [[The Hork-Bajir Chronicles, 0], [The Hork-Baj...  \n",
       "3     [[Laleli Mosque, 0], [Esma Sultan Mansion, 0]]  \n",
       "4  [[Big Stone Gap (film), 0], [Adriana Trigiani,...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotpot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17cdb34a-83a8-460a-a310-7352b26f4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpot_df.to_csv('processed_hotpot_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d6778-b2f9-42c7-950e-0ba505fc121d",
   "metadata": {},
   "source": [
    "## Step 1: Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be25ef-37a0-49c7-9fd4-46e7ea86e75a",
   "metadata": {},
   "source": [
    "### We will store context in ChromaDb with chunking, for this task we will use 256 as our chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2a86b50-8171-443e-8922-6809a94d5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_qasper_to_chroma(qasper_df, chroma_collection, character_splitter, token_splitter):\n",
    "    for id, group in qasper_df.groupby(\"id\"):\n",
    "        evidence = str(group.iloc[0][\"context\"])\n",
    "    \n",
    "        char_chunks = character_splitter.split_text(evidence)\n",
    "    \n",
    "        token_chunks = []\n",
    "        for chunk in char_chunks:\n",
    "            token_chunks.extend(token_splitter.split_text(chunk))\n",
    "    \n",
    "        if not token_chunks:\n",
    "            print(f\"Skipping paper {paper_id}: no chunks produced.\")\n",
    "            continue\n",
    "        \n",
    "        ids = [f\"{id}_{i}\" for i in range(len(token_chunks))]\n",
    "        question_ids = group[\"question_id\"].tolist()\n",
    "        metadatas = [\n",
    "            {\n",
    "                \"question_id\": id,\n",
    "            }\n",
    "            for _ in token_chunks\n",
    "        ]\n",
    "    \n",
    "        chroma_collection.add(\n",
    "            documents=token_chunks,\n",
    "            ids=ids,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "    \n",
    "    print(\"All papers processed and stored in Chroma.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1250d0c0-107d-49ce-bf4a-6c1c8ef22e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_hotpot_to_chroma(hotpot_df, chroma_collection, character_splitter, token_splitter):\n",
    "\n",
    "    for q_id, group in tqdm(hotpot_df.groupby(\"id\"), desc=\"Processing Hotpot QA\"):\n",
    "\n",
    "        row_context = group.iloc[0][\"context\"]\n",
    "\n",
    "        if isinstance(row_context, str):\n",
    "            try:\n",
    "                row_context = ast.literal_eval(row_context)\n",
    "            except Exception:\n",
    "                row_context = [(\"No Title\", [row_context])]\n",
    "\n",
    "        context_blocks = []\n",
    "        for title, paragraphs in row_context:\n",
    "            section_text = \"\\n\".join(paragraphs) if isinstance(paragraphs, list) else str(paragraphs)\n",
    "            context_blocks.append(f\"{title}\\n{section_text}\")\n",
    "\n",
    "        full_text = \"\\n\\n\".join(context_blocks)\n",
    "        char_chunks = character_splitter.split_text(full_text)\n",
    "\n",
    "        token_chunks = []\n",
    "        for chunk in char_chunks:\n",
    "            token_chunks.extend(token_splitter.split_text(chunk))\n",
    "\n",
    "        if not token_chunks:\n",
    "            print(f\"Skipping question {q_id}: no context found produced.\")\n",
    "            continue\n",
    "\n",
    "        ids = [f\"{q_id}_{i}\" for i in range(len(token_chunks))]\n",
    "        metadatas = [{\"question_id\": q_id} for _ in token_chunks]\n",
    "\n",
    "        chroma_collection.add(\n",
    "            documents=token_chunks,\n",
    "            ids=ids,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "\n",
    "    print(\"All HotpotQA questions processed and stored in Chroma.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78c3122d-92f8-4d9c-9017-8bd2d84c9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_HOTPOT = \"HotpotQA\"\n",
    "DATASET_QASPER = \"Qasper\"\n",
    "\n",
    "TOKEN_CHUNK_SIZE = 256\n",
    "TOKEN_CHUNK_OVERLAP = 10\n",
    "\n",
    "CHAR_CHUNK_SIZE = 1000\n",
    "CHAR_CHUNK_OVERLAP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c722c78d-6e96-4502-bb0b-f8dc2f4ecbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_loader_pipeline(DATASET_TYPE, collection, dataframe):\n",
    "    \n",
    "    character_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=CHAR_CHUNK_SIZE,\n",
    "        chunk_overlap=CHAR_CHUNK_OVERLAP\n",
    "    )\n",
    "\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(\n",
    "        chunk_overlap=TOKEN_CHUNK_OVERLAP,\n",
    "        tokens_per_chunk=TOKEN_CHUNK_SIZE\n",
    "    )\n",
    "\n",
    "    if DATASET_TYPE == DATASET_QASPER:\n",
    "        ingest_qasper_to_chroma(dataframe, collection, character_splitter, token_splitter)\n",
    "    elif DATASET_TYPE == DATASET_HOTPOT:\n",
    "        ingest_hotpot_to_chroma(dataframe, collection, character_splitter, token_splitter)\n",
    "    else:\n",
    "        print(\"Invalid Dataset Type\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa85f67a-dd8b-4846-8539-1041f4dc8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_collections(db_path: str, configs: dict, embedding_models: list):\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    collections = {}\n",
    "\n",
    "    for dataset_name, cfg in configs.items():\n",
    "        base_name = cfg[\"collection\"]\n",
    "        collections[dataset_name] = {}\n",
    "\n",
    "        for model_name in embedding_models:\n",
    "            short_model = model_name.split(\"/\")[-1]\n",
    "            collection_name = f\"{base_name}_{short_model}\"\n",
    "\n",
    "            try:\n",
    "                client.delete_collection(name=collection_name)\n",
    "                print(f\"Deleted old collection: {collection_name}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # create embedding function for this model\n",
    "            embedding_fn = SentenceTransformerEmbeddingFunction(model_name=model_name)\n",
    "\n",
    "            # create and store the collection\n",
    "            coll = client.create_collection(\n",
    "                name=collection_name,\n",
    "                embedding_function=embedding_fn\n",
    "            )\n",
    "\n",
    "            collections[dataset_name][short_model] = coll\n",
    "            print(f\" Created collection '{collection_name}' using '{model_name}'\")\n",
    "\n",
    "    return collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6e8a4-c610-4870-ab3e-b796f403e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted old collection: hpqa_data_collection_all-MiniLM-L6-v2\n",
      " Created collection 'hpqa_data_collection_all-MiniLM-L6-v2' using 'sentence-transformers/all-MiniLM-L6-v2'\n",
      "Deleted old collection: hpqa_data_collection_all-mpnet-base-v2\n",
      " Created collection 'hpqa_data_collection_all-mpnet-base-v2' using 'sentence-transformers/all-mpnet-base-v2'\n",
      "Deleted old collection: hpqa_data_collection_all-MiniLM-L12-v2\n",
      " Created collection 'hpqa_data_collection_all-MiniLM-L12-v2' using 'sentence-transformers/all-MiniLM-L12-v2'\n",
      "Deleted old collection: qasper_data_collection_all-MiniLM-L6-v2\n",
      " Created collection 'qasper_data_collection_all-MiniLM-L6-v2' using 'sentence-transformers/all-MiniLM-L6-v2'\n",
      "Deleted old collection: qasper_data_collection_all-mpnet-base-v2\n",
      " Created collection 'qasper_data_collection_all-mpnet-base-v2' using 'sentence-transformers/all-mpnet-base-v2'\n",
      "Deleted old collection: qasper_data_collection_all-MiniLM-L12-v2\n",
      " Created collection 'qasper_data_collection_all-MiniLM-L12-v2' using 'sentence-transformers/all-MiniLM-L12-v2'\n",
      "Loading HotpotQA with model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hotpot QA: 100%|██████████| 7405/7405 [13:32<00:00,  9.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HotpotQA questions processed and stored in Chroma.\n",
      "Loading HotpotQA with model: all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hotpot QA:  10%|█         | 754/7405 [05:55<51:37,  2.15it/s]  "
     ]
    }
   ],
   "source": [
    "DATASET_CONFIGS = {\n",
    "    \"HotpotQA\": {\n",
    "        \"collection\": \"hpqa_data_collection\"\n",
    "    },\n",
    "    \"Qasper\": {\n",
    "        \"collection\": \"qasper_data_collection\"\n",
    "    }\n",
    "}\n",
    "\n",
    "EMBEDDING_MODELS = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "]\n",
    "\n",
    "collections = create_chroma_collections(\"./ChromaDb\", DATASET_CONFIGS, EMBEDDING_MODELS)\n",
    "\n",
    "# Example keys: collections[\"HotpotQA\"][\"all-MiniLM-L6-v2\"]\n",
    "\n",
    "hotpot_df = pd.read_csv(\"processed_hotpot_df.csv\")\n",
    "qasper_df = pd.read_csv(\"processed_qasper_data.csv\")\n",
    "\n",
    "for model_key, hotpot_collection in collections[\"HotpotQA\"].items():\n",
    "    print(f\"Loading HotpotQA with model: {model_key}\")\n",
    "    run_data_loader_pipeline(DATASET_HOTPOT, hotpot_collection, hotpot_df)\n",
    "\n",
    "for model_key, qasper_collection in collections[\"Qasper\"].items():\n",
    "    print(f\"Loading Qasper with model: {model_key}\")\n",
    "    run_data_loader_pipeline(DATASET_QASPER, qasper_collection, qasper_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c101fa06-d3c9-4d96-ba40-607100e9908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421ff50-9be6-45cd-94f6-e723baf74193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
